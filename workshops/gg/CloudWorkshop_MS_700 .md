![](images/200/image1.png)





## Introduction


# Lab 7: Review	Performance	Metrics	Server	
![](images/Lab7/image7_0.png)

Note:	Although you can enable	Performance	Metric Server during a deployment, the interface and associated	RESTful	APIs are covered under the	Oracle GoldenGate Management Pack License.	

# Overview 

Time to Complete 
- Perform all tasks – 20 Minutes 
- Prerequisites 
Before you begin this tutorial, you should 
•	Have a general understanding of RDBMS and data integration concepts. 
•	Have a general understanding of ETL and data synchronization concepts. 

Lab Environment 
For this lab, the Data Integration Platform Cloud and the client environment are contained within on environment for simplicity.  Most user interactions with Data Integration Platform Cloud will be through a browser installed on your local machine (Chrome preferred, Firefox is also supported).   

# Task 0: Performance Metric Server 

## Logging Into Oracle Cloud Performance Metric Server Instance

1. In your web browser, Open the ServiceManager Page

![](images/Lab7/image7_1.png)

-  Enter your user name and password, then click Sign In.

If the screensaver is on just press “enter” to open the login screen. 
 
2. Select the Performance Metric Server link from the deployment area. This will open the Performance Metric Server page. 
![](images/Lab7/image7_2.png)

3. Notice that all processes with the deployment are listed at the top.  These are clickable boxes that will take you into the process detailss

![](images/Lab7/image7_3.png)

4. Drill in on the Extract process. This will provide you with real-time information about what the process is doing.   

Note: This information is not retained in a repository, so this is only real-time.  Historical information can be gained from other Oracle products like Oracle Enterprise Manager. 

![](images/Lab7/image7_4.png)








![](images/600/image600_5.png)

- Go to Applications > Internet and click Google Chrome 

![](images/600/image600_6.png)
- In Chrome, open up DIPC Home bookmark or go to \<hostname>:7003/dicloud/login.html
- Login with weblogic/#!hyper1on!#  

After a few seconds, the following page should appear – 

![](images/600/image600_7.png)

3. Use DIPC Demo Client 
- This hands-on lab uses a JDBC utility client that was built specifically for this demo.  This client is NOT part of DIPC, however it does help visualize the 
Synchronize Data and ODI Execution Job process 
- Open a Terminal 

![](images/600/image600_8.png)

- From the home directory execute ./startDIPCDemoClient.sh 
![](images/600/image600_9.png)

- Demo Client will open up and should be populated with the following data 

![](images/600/image600_10.png)

# Task 1: Create ODI Execution Task 

1. Click on Home in Navigation Bar
![](images/600/image600_11.png)

2. Click on ODI Execution (you may need to scroll right in the carousel to see it)
![](images/600/image600_12.png)

3. The ODI Execution Task screen appears 
![](images/600/image600_13.png)

4. Enter
•	Name: Load Sales DW 
•	Description: Execute ODI Scenario to load OLTP data into DW 

5.	Under Connections click on Import to import a deployment archive created in ODI Studio that contains the Scenario we want to execute 
- Navigate to DIPC/DIPC 18.2.3 and select LD_SALES_DIPC_18.2.3.zip 
![](images/600/image600_14.png)

- Click Open and wait for the import operation to complete (this will take about 2-3 minutes) 
- Click on the Scenario Name drop-down and select LD_TRG_SALES 001 
![](images/600/image600_15.png)

This scenario joins SRC_ORDERS and SRC_ORDER_LINES, aggregates the data, filters for ORDERS with Status of ‘CLO’ as well as performs an incremental update. 
So only replicated rows that have a status of ‘CLO’ closed, will be loaded to the target Sales DW. 

6.	In the Connection table pick the following Connections and Schemas: 
- ODI_DEMO_TRG:  
- Connection: Sync Target 
- Schema: ODI_TGT 

- ODI_DEMO_SRC 
- Connection: Sync Target 
- Schema: DIPC_TGT 
![](images/600/image600_16.png)
7.	Click on Save & Run to execute the Task  
8.	You will be redirected to the Jobs page and you will see a notification that a new Job execution started 
9.	When the Job appears in the list you can click on it to get more details 
![](images/600/image600_17.png)
10.	The Job Details contains all the details about the scenario execution in ODI 
![](images/600/image600_18.png)

You can click on any Step in the Job Execution to review the code generated by ODI 
![](images/600/image600_19.png)

When the Job has completed successfully you will see that the data has been fully loaded into the Target Sales Data Warehouse using OPI through the ODI execution task in the DIPC console
![](images/600/image600_20.png)

# Summary
In this lab, we have seen how MicroServices running in DIPC can work hand in hand to implement an end-to-end data flow.   